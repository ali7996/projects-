{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f78b699a",
      "metadata": {
        "id": "f78b699a"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdfe7ada",
      "metadata": {
        "id": "bdfe7ada"
      },
      "source": [
        "You should process some texts using [NLTK](https://www.nltk.org/) or [spaCy](https://spacy.io/) libraries (ideally both). In particular, you should do the following:\n",
        "- Load the `harry_potter` book. You can find this text corpus in the datasets folder.\n",
        "- Segment the text of the book into sentences. How many sentences does this book have?\n",
        "- Compute the frequency of each token in the book. What are the most frequent tokens?\n",
        "- Choose a sentence from the book. Analyze this chosen sentence by\n",
        "    - Calculating all [n-grams](https://en.wikipedia.org/wiki/N-gram).\n",
        "    - Finding [POS tags](https://en.wikipedia.org/wiki/Part-of-speech_tagging) of tokens.\n",
        "    - [Stemming](https://en.wikipedia.org/wiki/Stemming) and [lemmatizing](https://en.wikipedia.org/wiki/Lemmatisation) tokens.\n",
        "- Check the documentation to identify the most important hyperparameters, attributes, and methods. Use them in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import liberaries**"
      ],
      "metadata": {
        "id": "Mb0anz1TnX7D"
      },
      "id": "Mb0anz1TnX7D"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpi2-K9WneDj",
        "outputId": "70fd4852-203e-459f-a43e-abdd1495124e"
      },
      "id": "Kpi2-K9WneDj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **load the book**"
      ],
      "metadata": {
        "id": "l3oL55kAm3A4"
      },
      "id": "l3oL55kAm3A4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8d7e3f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8d7e3f0",
        "outputId": "0bf04970-cdb6-4319-c49d-18b8fbe77cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER ONE THE BOY WHO LIVED \n",
            "\n",
            "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. \n",
            "\n",
            "Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere. \n",
            "\n",
            "The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn't think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley's sister, b\n"
          ]
        }
      ],
      "source": [
        "f=open('/content/harry_potter.txt')\n",
        "text=f.read()\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **sentence segmentation**"
      ],
      "metadata": {
        "id": "Fsbf8BQwpSI2"
      },
      "id": "Fsbf8BQwpSI2"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_sentences=nltk.sent_tokenize(text)\n",
        "print('number of sentences',len(nltk_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cXMa7CunBpN",
        "outputId": "9f4bb8cd-e990-4b56-b902-701b11fe0177"
      },
      "id": "9cXMa7CunBpN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of sentences 6394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compute the frequency**"
      ],
      "metadata": {
        "id": "DgVmTZ8yJLwh"
      },
      "id": "DgVmTZ8yJLwh"
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens={}\n",
        "for s in nltk_sentences:\n",
        "  sent_tokens=nltk.word_tokenize(s)\n",
        "  for t in sent_tokens:\n",
        "    if t not in all_tokens :\n",
        "        all_tokens[t]=0\n",
        "    all_tokens[t]+=1\n",
        "frequent_tokens=sorted(all_tokens,key =all_tokens.get,reverse=True)[:20]\n",
        "for t in frequent_tokens: \n",
        "  print(t,all_tokens[t])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zeosrbg9vBhp",
        "outputId": "5e044354-7c7d-458b-be18-43b27a774a55"
      },
      "id": "Zeosrbg9vBhp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", 5658\n",
            ". 5119\n",
            "the 3310\n",
            "'' 2441\n",
            "`` 2307\n",
            "to 1845\n",
            "and 1804\n",
            "a 1578\n",
            "Harry 1323\n",
            "was 1253\n",
            "of 1242\n",
            "he 1208\n",
            "'s 997\n",
            "in 933\n",
            "I 919\n",
            "it 897\n",
            "his 896\n",
            "you 837\n",
            "n't 826\n",
            "said 793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculating all N-grams.**"
      ],
      "metadata": {
        "id": "hpWDsRLOJYYt"
      },
      "id": "hpWDsRLOJYYt"
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting one sentence \n",
        "sentence= nltk_sentences[10]\n",
        "print(sentence)\n",
        "#tokenaizing e selected  sentence \n",
        "sentence_tokens=nltk.tokenize.word_tokenize(sentence)\n",
        "#calculating N-grams \n",
        "ngrams=list(nltk.ngrams(sentence_tokens,3))\n",
        "ngrams\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0hqRdx9EWZ2",
        "outputId": "fbdb6743-6ea4-4fe6-cc89-b2e70a18bca0"
      },
      "id": "E0hqRdx9EWZ2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dursleys knew that the Potters had a small son, too, but they had never even seen him.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'Dursleys', 'knew'),\n",
              " ('Dursleys', 'knew', 'that'),\n",
              " ('knew', 'that', 'the'),\n",
              " ('that', 'the', 'Potters'),\n",
              " ('the', 'Potters', 'had'),\n",
              " ('Potters', 'had', 'a'),\n",
              " ('had', 'a', 'small'),\n",
              " ('a', 'small', 'son'),\n",
              " ('small', 'son', ','),\n",
              " ('son', ',', 'too'),\n",
              " (',', 'too', ','),\n",
              " ('too', ',', 'but'),\n",
              " (',', 'but', 'they'),\n",
              " ('but', 'they', 'had'),\n",
              " ('they', 'had', 'never'),\n",
              " ('had', 'never', 'even'),\n",
              " ('never', 'even', 'seen'),\n",
              " ('even', 'seen', 'him'),\n",
              " ('seen', 'him', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **POS Tagging**"
      ],
      "metadata": {
        "id": "MvO5ILZMOAOa"
      },
      "id": "MvO5ILZMOAOa"
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence)\n",
        "tags=nltk.pos_tag(sentence_tokens)\n",
        "tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3AVhwI-N_28",
        "outputId": "a0088c6d-01bc-4fb5-f8dd-490cc579e6f2"
      },
      "id": "j3AVhwI-N_28",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dursleys knew that the Potters had a small son, too, but they had never even seen him.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('Dursleys', 'NNP'),\n",
              " ('knew', 'VBD'),\n",
              " ('that', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('Potters', 'NNPS'),\n",
              " ('had', 'VBD'),\n",
              " ('a', 'DT'),\n",
              " ('small', 'JJ'),\n",
              " ('son', 'NN'),\n",
              " (',', ','),\n",
              " ('too', 'RB'),\n",
              " (',', ','),\n",
              " ('but', 'CC'),\n",
              " ('they', 'PRP'),\n",
              " ('had', 'VBD'),\n",
              " ('never', 'RB'),\n",
              " ('even', 'RB'),\n",
              " ('seen', 'VBN'),\n",
              " ('him', 'PRP'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming**"
      ],
      "metadata": {
        "id": "eqdqPYsUZI8p"
      },
      "id": "eqdqPYsUZI8p"
    },
    {
      "cell_type": "code",
      "source": [
        "sentince=nltk_sentences[1]\n",
        "entence_tokens=nltk.tokenize.word_tokenize(sentence)\n",
        "print(sentence)\n",
        "print()\n",
        "porter=nltk.stem.PorterStemmer()\n",
        "for word in sentence_tokens :\n",
        "  print(word,'\\t\\t\\t',porter.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mENXXFtdZG0Z",
        "outputId": "eb2dc7dc-2eef-4e03-a69d-7ffdbe758eea"
      },
      "id": "mENXXFtdZG0Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dursleys knew that the Potters had a small son, too, but they had never even seen him.\n",
            "\n",
            "The \t\t\t the\n",
            "Dursleys \t\t\t dursley\n",
            "knew \t\t\t knew\n",
            "that \t\t\t that\n",
            "the \t\t\t the\n",
            "Potters \t\t\t potter\n",
            "had \t\t\t had\n",
            "a \t\t\t a\n",
            "small \t\t\t small\n",
            "son \t\t\t son\n",
            ", \t\t\t ,\n",
            "too \t\t\t too\n",
            ", \t\t\t ,\n",
            "but \t\t\t but\n",
            "they \t\t\t they\n",
            "had \t\t\t had\n",
            "never \t\t\t never\n",
            "even \t\t\t even\n",
            "seen \t\t\t seen\n",
            "him \t\t\t him\n",
            ". \t\t\t .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lemmitization**"
      ],
      "metadata": {
        "id": "VoEeLUaPa7S1"
      },
      "id": "VoEeLUaPa7S1"
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
        "for t in sentence_tokens:\n",
        "  print(t,'\\t \\t',lemmatizer.lemmatize(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPeZ0FKPbA2k",
        "outputId": "acfa30cc-c984-4e08-8694-47cd6a4a66d8"
      },
      "id": "VPeZ0FKPbA2k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The \t \t The\n",
            "Dursleys \t \t Dursleys\n",
            "knew \t \t knew\n",
            "that \t \t that\n",
            "the \t \t the\n",
            "Potters \t \t Potters\n",
            "had \t \t had\n",
            "a \t \t a\n",
            "small \t \t small\n",
            "son \t \t son\n",
            ", \t \t ,\n",
            "too \t \t too\n",
            ", \t \t ,\n",
            "but \t \t but\n",
            "they \t \t they\n",
            "had \t \t had\n",
            "never \t \t never\n",
            "even \t \t even\n",
            "seen \t \t seen\n",
            "him \t \t him\n",
            ". \t \t .\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}